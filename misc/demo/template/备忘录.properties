######################################################################
############################ 常用密码和工具 #############################
######################################################################
# Harbor密码
admin/admin

# Redis连接授权密码
auth dahua@b0HM1G3X2l

# 宝塔密码
root.acc/root.pwd156558

# 开启开机自启
systemctl enable nginx

# 关闭开机自启
systemctl diaable nginx

# Markdown创建
<font face="微软雅黑" color="red" size="4">

# 查看SO库有哪些接口方法
nm -D libXXX.so

# 跨主机复制文件
rsync -rl root@hadoop104:/opt/mod/nginx-1.19.0 ./
scp -r root@hadoop104:/demo.tar.gz ./

# 查询命令被安装到哪个目录
whereis nginx

# 改变文件夹的所有者和所在组
sudo chown alan:alan mod -R
sudo chown alan:alan sof -R

# 启动nginx服务
/opt/mod/nginx-1.19.0/sbin/nginx
nginx

# 停止nginx服务
/opt/mod/nginx-1.19.0/sbin/nginx -s quit
nginx -s quit

# 重新加载配置文件
/opt/mod/nginx-1.19.0/sbin/nginx -s reload
nginx -s reload

# 指定nginx.conf配置文件路径
/opt/mod/nginx-1.19.0/sbin/nginx -c nginx.conf
nginx -c nginx.conf


######################################################################
############################## K8S常用命令 #############################
######################################################################
# K8S初始化命令
kubeadm init \
  --apiserver-advertise-address=192.168.47.104 \
  --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers \
  --kubernetes-version=v1.21.10 \
  --service-cidr=10.96.0.0/16 \
  --pod-network-cidr=10.244.0.0/16
  
# 查看命令空间下的所有pod：
kubectl get pods -w -n cloudspace | grep fix

# 编辑容器镜像地址 直接重新拉起容器
kubectl -n cloudspace edit sts pc-offline-dossier-fix

# 使用kubectl cp复制文件到容器
kubectl cp ./dossierfix.jar cloudspace/pc-offline-dossier-fix-0:/


######################################################################
############################# KAFKA常用命令 ############################
######################################################################
# 查看kafka消费到的偏移量
sh /cloud/service/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 10.38.21.56:9092 --group fc_face_body_valid_record_group --describe

# 将kafka的偏移量置于最新
sh /cloud/service/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 10.38.21.56:9092  --group fc_face_body_valid_record_group --topic fc_face_body_valid_record --reset-offsets --all-topics --to-latest --execute


######################################################################
############################# HBASE常用命令 ############################
######################################################################
# 清空hbase表数据 保留表和表结构
truncate_preserve 'p_face_dossier'

# hbase解析二进制数据
get 'p_face_dossier', '63915134209371487231363534', {COLUMN => ['info:ageGroup:toInt', 'info:gender:toInt']}


######################################################################
############################# Yarn常用命令 #############################
######################################################################
# yarn鉴权
kinit hadoop/1q2w3e4r_

# 列出所有正在运行的任务
yarn application -list

# 根据Application状态过滤：yarn application -list -appStates （所有状态：ALL、NEW、NEW_SAVING、SUBMITTED、ACCEPTED、RUNNING、FINISHED、FAILED、KILLED）
yarn application -list -appStates FINISHED

# kill掉Application
yarn application -kill application_1612577921195_0001

# 查看Application日志
yarn logs -applicationId application_1612577921195_0001

# 查询Container日志
yarn logs -applicationId application_1612577921195_0001 -containerId container_1612577921195_0001_01_000001

# 列出所有Application尝试的列表
yarn applicationattempt -list application_1612577921195_0001

# 打印ApplicationAttemp状态
yarn applicationattempt -status appattempt_1612577921195_0001_000001

# 只有在任务跑的途中才能看到container的状态
# 列出所有Container
yarn container -list appattempt_1612577921195_0001_000001

# 打印Container状态
yarn container -status container_1612577921195_0001_01_000001

# 列出所有节点
yarn node -list -all

# 加载队列配置
yarn rmadmin -refreshQueues

# 打印队列信息
yarn queue -status default


######################################################################
########################## Spark&Hive常用命令 ##########################
######################################################################
# 使用beeline连接hive:
beeline -u "jdbc:hive2://localhost:10000/rljl;principal=hadoop/hdp-hive-hdp-hive-server2-0.hdp-hive-hdp-hive-server2.cloudspace.svc.cluster.local@DAHUA.COM"
beeline -u jdbc:hive2://hadoop101:10000/default -n root

# spark-shell支持(hive-site.xml必须在spark安装目录的conf下）
spark-shell --master yarn --conf spark.yarn.queue=fcqueue --executor-memory 1G --executor-cores 2 --num-executors 2 --driver-memory 1G --driver-cores 1
spark-shell --master yarn --conf spark.yarn.queue=default --executor-memory 1G --executor-cores 2 --num-executors 2 --driver-memory 1G --driver-cores 1 

# spark-sql支持(hive-site.xml必须在spark安装目录的conf下）
spark-sql --master yarn --queue fcqueue --database rljl --executor-cores 2 --num-executors 2 --executor-memory 1G --conf "spark.hadoop.hive.cli.print.header=true"
spark-sql --master yarn --queue default --database default --executor-cores 2 --num-executors 2 --executor-memory 1G --conf "spark.hadoop.hive.cli.print.header=true"

# thriftserver(hive-site.xml必须在spark安装目录的conf下）
start-thriftserver.sh --master yarn --conf spark.yarn.queue=default --executor-memory 1G --executor-cores 2 --num-executors 2 --driver-memory 1G --driver-cores 1
beeline -u jdbc:hive2://hadoop101:10001/default -n root















